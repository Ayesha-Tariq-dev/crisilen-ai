// src/services/openaiService.js
import { mockAnalysisResults } from '../data/sampleCrisisData.js';

export class OpenAIService {
  constructor() {
    this.apiKey = process.env.REACT_APP_OPENAI_API_KEY;
    this.baseUrl = 'https://api.openai.com/v1';
    this.model = 'gpt-3.5-turbo';
    this.maxRetries = 3;
    this.requestQueue = [];
    this.isProcessing = false;
    this.rateLimit = {
      remaining: 3,
      resetTime: Date.now(),
      requestsPerMin: 3
    };
  }

  async analyzeCrisis(crisisText, location = '', type = '', crisisId = null) {
    return new Promise((resolve, reject) => {
      this.requestQueue.push({
        crisisText,
        location,
        type,
        crisisId,
        resolve,
        reject
      });
      
      this.processQueue().catch(console.error);
    });
  }

  async processQueue() {
    if (this.isProcessing || this.requestQueue.length === 0) return;
    
    this.isProcessing = true;
    
    try {
      while (this.requestQueue.length > 0) {
        const request = this.requestQueue[0];
        const now = Date.now();

        if (this.rateLimit.remaining === 0 && now < this.rateLimit.resetTime) {
          const waitTime = this.rateLimit.resetTime - now;
          await new Promise(resolve => setTimeout(resolve, waitTime));
          this.rateLimit.remaining = this.rateLimit.requestsPerMin;
        }

        try {
          const result = await this.makeRequest(request);
          request.resolve(result);
        } catch (error) {
          if (error.status === 429) {
            this.rateLimit.remaining = 0;
            this.rateLimit.resetTime = Date.now() + 60000;
            continue;
          }
          request.reject(error);
        }

        this.requestQueue.shift();
        this.rateLimit.remaining--;

        if (this.requestQueue.length > 0) {
          await new Promise(resolve => setTimeout(resolve, 60000 / this.rateLimit.requestsPerMin));
        }
      }
    } finally {
      this.isProcessing = false;
    }
  }

  async makeRequest(request) {
    if (request.type === 'summary') {
      return this.generateSummary(request.data);
    }

    const { crisisText, location, type, crisisId } = request;

    if (!this.apiKey) {
      console.log('üé≠ Using mock AI analysis - no API key');
      return this.getMockAnalysis(crisisText, type, crisisId);
    }

    let attempt = 0;
    
    while (attempt < this.maxRetries) {
      try {
        console.log('ü§ñ Analyzing crisis with OpenAI...');
        
        if (attempt > 0) {
          const backoffTime = Math.min(1000 * Math.pow(2, attempt), 8000);
          console.log(`Retry attempt ${attempt + 1} after ${backoffTime}ms backoff...`);
          await new Promise(resolve => setTimeout(resolve, backoffTime));
        }

        const response = await fetch(`${this.baseUrl}/chat/completions`, {
          method: 'POST',
          headers: {
            'Authorization': `Bearer ${this.apiKey}`,
            'Content-Type': 'application/json',
          },
          body: JSON.stringify({
            model: this.model,
            messages: [
              {
                role: 'system',
                content: this.getSystemPrompt()
              },
              {
                role: 'user',
                content: this.formatAnalysisPrompt(crisisText, location, type)
              }
            ]
          })
        });

        if (!response.ok) {
          const error = new Error('OpenAI API error: ' + response.status);
          error.status = response.status;
          throw error;
        }

        const data = await response.json();
        let analysis = this.parseAnalysisResponse(data);
        
        if (!analysis) {
          console.log('üé≠ Falling back to mock analysis');
          return this.getMockAnalysis(crisisText, type, crisisId);
        }

        return this.enrichAnalysis(analysis, type);

      } catch (error) {
        attempt++;
        console.error('Error on attempt', attempt, error);
        
        if (error.status === 429 || attempt === this.maxRetries) {
          console.log('üé≠ Falling back to mock analysis after error');
          return this.getMockAnalysis(crisisText, type, crisisId);
        }
      }
    }

    // If we get here, all attempts failed
    return this.getMockAnalysis(crisisText, type, crisisId);
  }

  async generateSummary(crisisDataArray) {
    return mockAnalysisResults[0];
  }

  getSystemPrompt() {
    return `You are a crisis analysis AI expert. Analyze crisis reports and extract structured information.

RESPOND ONLY IN VALID JSON FORMAT with these exact fields:
{
  "urgency": number (1-10, where 10 is most critical),
  "estimatedCasualties": "string description",
  "resourcesNeeded": ["array", "of", "resources"],
  "immediateActions": ["array", "of", "actions"],
  "riskLevel": "Critical|High|Medium|Low",
  "stakeholders": ["array", "of", "organizations"],
  "confidence": number (0.0-1.0)
}`;
  }

  formatAnalysisPrompt(text, location, type) {
    return `Analyze this crisis:
Location: ${location || 'Unknown'}
Type: ${type || 'Unspecified'}
Report: ${text}

Provide a structured analysis in the specified JSON format.`;
  }

  parseAnalysisResponse(data) {
    try {
      const content = data.choices[0].message.content;
      return JSON.parse(content);
    } catch (error) {
      console.error('‚ùå Error parsing OpenAI response:', error);
      return null;
    }
  }

  enrichAnalysis(analysis, type) {
    if (!analysis) {
      return this.getMockAnalysis('', type);
    }
    return {
      ...analysis,
      timestamp: new Date().toISOString(),
      source: 'openai'
    };
  }

  getMockAnalysis(text, type, crisisId = null) {
    return mockAnalysisResults[0];
  }
}